{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Table of Contents\n",
    "* [1. Introduction](#1.-Introduction)\n",
    "\t* [1.1 Cluster Computing](#1.1-Cluster-Computing)\n",
    "\t* [1.2 Distributed Resource Managers](#1.2-Distributed-Resource-Managers)\n",
    "* [2. Usage of DRMs](#2.-Usage-of-DRMs)\n",
    "\t* [2.1 Single Job Configuration](#2.1-Single-Job-Configuration)\n",
    "\t* [2.2 Array and Parallel jobs](#2.2-Array-and-Parallel-jobs)\n",
    "\t* [2.3 DRMAA](#2.3-DRMAA)\n",
    "* [3. Complementary approaches](#3.-Complementary-approaches)\n",
    "\t* [3.1 Jug: Simple Task Based Parallelism](#3.1-Jug:-Simple-Task-Based-Parallelism)\n",
    "\t* [3.2 IPython Parallel](#3.2-IPython-Parallel)\n",
    "\t* [3.3 Modern Cluster Computing](#3.3-Modern-Cluster-Computing)\n",
    "* [4. Conclusion](#4.-Conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this IPython/Jupyter Notebook (which was itself created and executed in a computing cluster) we will explore advances usages of Distributed Resource Managers (DRMs) and its limitations for common parallel task. Then, some complementary approaches will also be reviewed. In this section, the cluster computing and DRM concepts are introduced which will be throughly used along this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Cluster Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both in science and industry, the use of computer clusters for speeding up data processing tasks and centralising computing resources is a common practise. A computer cluster can be generally defined as set of interconnected computers (i.e. nodes) that can work together to perform coordinated tasks. Even though the design and scale of a computer cluster depend of the implementation and use requirements, apart from being in the same network, most modern computing clusters have the common characteristic that they share a clustered file system, which can be used for storage and sharing heterogeneus data between nodes and cluster users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For even larger problems that can be distributed, grid computing is a different approach, which uses a collection of heterogeneous computing resources (e.g. cluster nodes) at different locations but loosely connected. Depending on the scale and type of problem, using a computer cluster can be more convenient and faster than grid computing, because of data locality and easier resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Distributed Resource Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to manage the availiable resources with heterogeneous workloads, a distributed resource manager (DRM, also referred as batch-queuing system) is usually installed at computing clusters. This system is in charge of job scheduling and computing resource management (e.g. memory and disk) for all the cluster user submissions. Some commonly used DRMs include SGE (Sun Grid Engine derivatives), PBS (Portable Batch System), HTCondor or SLURM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While batch-queuing systems are very useful for cluster administration and simple job submission and scheduling, the job submission interfaces commonly provided are not convenient for the execution of complex coordinated tasks. In this work, we will start by reviewing advanced use cases of DRMs and then we will explore some complementary modern approaches to solve their limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Usage of DRMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, some advanced use cases of [SGE batch-queuing system](https://arc.liv.ac.uk/trac/SGE) (that is the distributed resouce manager installed at [IFCA cluster](https://grid.ifca.es/wiki/Cluster)) will be demonstrated. Son of Grid Engine is a open source community continuation of the Sun Grid Engine project, a more extensive description of uses and capalibities is provided at [SoGE webpage](http://arc.liv.ac.uk/SGE/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Single Job Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most basic command in any DRM is the one used for submiting jobs to the cluster queue, which in case of SGE is *qsub*. Apart from *qsub*, SGE provides *qrsh* and *qlogin* for interactive sessions at one of the computing nodes. Job configuration parameters as project, wall clock time or available memory can be configured with different arguments either in a configuration file (i.e. .seg_request), the job script itself or as command-line flags. In the following example, a simple SGE scriptis used to calculate pi with arbitrary precision (e.g. 10000 digits) using [Machin's formula](http://en.wikipedia.org/wiki/John_Machin). In this case, the precision up to calculate pi can be configured with a command line argument when *qsub* is called. Many job configuration parameters are also specified in the configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n",
       "   \"http://www.w3.org/TR/html4/strict.dtd\">\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "  <title></title>\n",
       "  <meta http-equiv=\"content-type\" content=\"text/html; charset=None\">\n",
       "  <style type=\"text/css\">\n",
       "td.linenos { background-color: #f0f0f0; padding-right: 10px; }\n",
       "span.lineno { background-color: #f0f0f0; padding: 0 5px 0 5px; }\n",
       "pre { line-height: 125%; }\n",
       "body .hll { background-color: #ffffcc }\n",
       "body  { background: #f8f8f8; }\n",
       "body .c { color: #408080; font-style: italic } /* Comment */\n",
       "body .err { border: 1px solid #FF0000 } /* Error */\n",
       "body .k { color: #008000; font-weight: bold } /* Keyword */\n",
       "body .o { color: #666666 } /* Operator */\n",
       "body .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       "body .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       "body .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       "body .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       "body .gd { color: #A00000 } /* Generic.Deleted */\n",
       "body .ge { font-style: italic } /* Generic.Emph */\n",
       "body .gr { color: #FF0000 } /* Generic.Error */\n",
       "body .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       "body .gi { color: #00A000 } /* Generic.Inserted */\n",
       "body .go { color: #888888 } /* Generic.Output */\n",
       "body .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       "body .gs { font-weight: bold } /* Generic.Strong */\n",
       "body .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       "body .gt { color: #0044DD } /* Generic.Traceback */\n",
       "body .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       "body .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       "body .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       "body .kp { color: #008000 } /* Keyword.Pseudo */\n",
       "body .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       "body .kt { color: #B00040 } /* Keyword.Type */\n",
       "body .m { color: #666666 } /* Literal.Number */\n",
       "body .s { color: #BA2121 } /* Literal.String */\n",
       "body .na { color: #7D9029 } /* Name.Attribute */\n",
       "body .nb { color: #008000 } /* Name.Builtin */\n",
       "body .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       "body .no { color: #880000 } /* Name.Constant */\n",
       "body .nd { color: #AA22FF } /* Name.Decorator */\n",
       "body .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       "body .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       "body .nf { color: #0000FF } /* Name.Function */\n",
       "body .nl { color: #A0A000 } /* Name.Label */\n",
       "body .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       "body .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       "body .nv { color: #19177C } /* Name.Variable */\n",
       "body .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       "body .w { color: #bbbbbb } /* Text.Whitespace */\n",
       "body .mf { color: #666666 } /* Literal.Number.Float */\n",
       "body .mh { color: #666666 } /* Literal.Number.Hex */\n",
       "body .mi { color: #666666 } /* Literal.Number.Integer */\n",
       "body .mo { color: #666666 } /* Literal.Number.Oct */\n",
       "body .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       "body .sc { color: #BA2121 } /* Literal.String.Char */\n",
       "body .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       "body .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       "body .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       "body .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       "body .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       "body .sx { color: #008000 } /* Literal.String.Other */\n",
       "body .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       "body .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       "body .ss { color: #19177C } /* Literal.String.Symbol */\n",
       "body .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       "body .vc { color: #19177C } /* Name.Variable.Class */\n",
       "body .vg { color: #19177C } /* Name.Variable.Global */\n",
       "body .vi { color: #19177C } /* Name.Variable.Instance */\n",
       "body .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "\n",
       "  </style>\n",
       "</head>\n",
       "<body>\n",
       "<h2></h2>\n",
       "\n",
       "<div class=\"highlight\"><pre><span class=\"c\">#! /bin/bash</span>\n",
       "\n",
       "<span class=\"c\"># HOWTO: run using qsub [parameters] pi_machin.sge n_digits</span>\n",
       "\n",
       "<span class=\"c\"># SGE configuration parameters</span>\n",
       "<span class=\"c\"># shell to use</span>\n",
       "<span class=\"c\">#$ -S /bin/bash</span>\n",
       "<span class=\"c\"># start from current dir</span>\n",
       "<span class=\"c\">#$ -cwd</span>\n",
       "<span class=\"c\"># job name</span>\n",
       "<span class=\"c\">#$ -N pi_machin</span>\n",
       "<span class=\"c\"># join error and output</span>\n",
       "<span class=\"c\">#$ -j y</span>\n",
       "<span class=\"c\"># output filename</span>\n",
       "<span class=\"c\">#$ -o pi_machin.out</span>\n",
       "<span class=\"c\"># memory required</span>\n",
       "<span class=\"c\">#$ -l mem_free=100M</span>\n",
       "<span class=\"c\"># wall clock time</span>\n",
       "<span class=\"c\">#$ -l h_rt=0:20:00</span>\n",
       "\n",
       "<span class=\"c\"># Precision for the calculation (from command arg)</span>\n",
       "<span class=\"nv\">scale</span><span class=\"o\">=</span><span class=\"nv\">$1</span>\n",
       "<span class=\"c\"># Obtain PI and echo to output (calculate using bc)</span>\n",
       "<span class=\"nb\">echo</span> <span class=\"s2\">&quot;scale=$scale; 16 * a (1/5) - 4 * a (1/239)&quot;</span> | bc -l\n",
       "</pre></div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import highlight_source_bash\n",
    "highlight_source_bash(\"pi_machin.sge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run an SGE job at the IFCA cluster, it is compulsory to specify a project (it could also have been included at the script file). Hence, the following command will send a job for the calculation of $\\pi$ with 10000 significant digits to the cluster queue. The *-l immediate* flag is for fast scheduling of short jobs while the *-P* flag defines the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job 5928932 (\"pi_machin\") has been submitted\r\n"
     ]
    }
   ],
   "source": [
    "!qsub -l immediate -P l.gaes pi_machin.sge 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *qsub* command confirms that the job has been submitted and returns a job-ID. We can check the status of running using the *qstat* command (the -u username flag is useful for listing only user jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!qstat -u $(whoami)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some minutes, the job has finished and we can check that the results have been written to *pi_machin.out*. The first few lines are shown at the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793238462643383279502884197169399375105820974944592307\\\r\n",
      "81640628620899862803482534211706798214808651328230664709384460955058\\\r\n",
      "22317253594081284811174502841027019385211055596446229489549303819644\\\r\n",
      "28810975665933446128475648233786783165271201909145648566923460348610\\\r\n",
      "45432664821339360726024914127372458700660631558817488152092096282925\\\r\n"
     ]
    }
   ],
   "source": [
    "ma!head -5 pi_machin.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful SGE command is *qacct*, which can be used to summarize resource consumption and accounting information about jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\r\n",
      "qname        cloud.short.q       \r\n",
      "hostname     cloudprv-04-1.ifca.es\r\n",
      "group        computacion         \r\n",
      "owner        pablodcm            \r\n",
      "project      l.gaes              \r\n",
      "department   computacion         \r\n",
      "jobname      pi_machin           \r\n",
      "jobnumber    5928932             \r\n",
      "taskid       undefined\r\n",
      "account      sge                 \r\n",
      "priority     -5                  \r\n",
      "qsub_time    Sun May  3 13:31:16 2015\r\n",
      "start_time   Sun May  3 13:31:19 2015\r\n",
      "end_time     Sun May  3 13:32:01 2015\r\n",
      "granted_pe   NONE                \r\n",
      "slots        1                   \r\n",
      "failed       0    \r\n",
      "exit_status  0                   \r\n",
      "ru_wallclock 42s\r\n",
      "ru_utime     41.501s\r\n",
      "ru_stime     0.535s\r\n",
      "ru_maxrss    1.758KB\r\n",
      "ru_ixrss     0.000B\r\n",
      "ru_ismrss    0.000B\r\n",
      "ru_idrss     0.000B\r\n",
      "ru_isrss     0.000B\r\n",
      "ru_minflt    37830               \r\n",
      "ru_majflt    3                   \r\n",
      "ru_nswap     0                   \r\n",
      "ru_inblock   512                 \r\n",
      "ru_oublock   184                 \r\n",
      "ru_msgsnd    0                   \r\n",
      "ru_msgrcv    0                   \r\n",
      "ru_nsignals  0                   \r\n",
      "ru_nvcsw     550                 \r\n",
      "ru_nivcsw    199                 \r\n",
      "cpu          42.036s\r\n",
      "mem          0.043GBs\r\n",
      "io           0.001GB\r\n",
      "iow          0.000s\r\n",
      "maxvmem      2.855MB\r\n",
      "arid         undefined\r\n",
      "category     -l h_rt=1200,immediate=TRUE,mem_free=100M\r\n"
     ]
    }
   ],
   "source": [
    "!qacct -j 5928932"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Array and Parallel jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous approach could be problematic when processing a large number of jobs (e.g. 100 or more), that are identical except some parameters (e.g. the name of the input file or a random seed). In principle, a shell script for each job\n",
    "could be created or the parameters can be passed as a command line arguments. However, SGE provides an unifying solution to manage this type of problems: array jobs. A SGE array job is an script that is going to be run multiple times and each execution is characterized with a task-ID enviroment variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mentioned use case is very common in many disciplines (e.g. mechanical simulations with different parameters or data analysis tasks with several input files). In this case, a real world data processing task from High Energy Physics is going to be used as an example. We have a compiled program, *process_tchain* that only selects the events in a [ROOT](https://root.cern.ch/drupal/) file that verify certain topological conditions (e.g. two leptons in the final state which pass some quality criteria). Using an array job configuration file, this processing task can be launched in at the same time over all data files listed a certain file (i.e. *inputfiles.txt*) only calling once the *qsub command*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n",
       "   \"http://www.w3.org/TR/html4/strict.dtd\">\n",
       "\n",
       "<html>\n",
       "<head>\n",
       "  <title></title>\n",
       "  <meta http-equiv=\"content-type\" content=\"text/html; charset=None\">\n",
       "  <style type=\"text/css\">\n",
       "td.linenos { background-color: #f0f0f0; padding-right: 10px; }\n",
       "span.lineno { background-color: #f0f0f0; padding: 0 5px 0 5px; }\n",
       "pre { line-height: 125%; }\n",
       "body .hll { background-color: #ffffcc }\n",
       "body  { background: #f8f8f8; }\n",
       "body .c { color: #408080; font-style: italic } /* Comment */\n",
       "body .err { border: 1px solid #FF0000 } /* Error */\n",
       "body .k { color: #008000; font-weight: bold } /* Keyword */\n",
       "body .o { color: #666666 } /* Operator */\n",
       "body .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       "body .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       "body .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       "body .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       "body .gd { color: #A00000 } /* Generic.Deleted */\n",
       "body .ge { font-style: italic } /* Generic.Emph */\n",
       "body .gr { color: #FF0000 } /* Generic.Error */\n",
       "body .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       "body .gi { color: #00A000 } /* Generic.Inserted */\n",
       "body .go { color: #888888 } /* Generic.Output */\n",
       "body .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       "body .gs { font-weight: bold } /* Generic.Strong */\n",
       "body .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       "body .gt { color: #0044DD } /* Generic.Traceback */\n",
       "body .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       "body .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       "body .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       "body .kp { color: #008000 } /* Keyword.Pseudo */\n",
       "body .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       "body .kt { color: #B00040 } /* Keyword.Type */\n",
       "body .m { color: #666666 } /* Literal.Number */\n",
       "body .s { color: #BA2121 } /* Literal.String */\n",
       "body .na { color: #7D9029 } /* Name.Attribute */\n",
       "body .nb { color: #008000 } /* Name.Builtin */\n",
       "body .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       "body .no { color: #880000 } /* Name.Constant */\n",
       "body .nd { color: #AA22FF } /* Name.Decorator */\n",
       "body .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       "body .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       "body .nf { color: #0000FF } /* Name.Function */\n",
       "body .nl { color: #A0A000 } /* Name.Label */\n",
       "body .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       "body .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       "body .nv { color: #19177C } /* Name.Variable */\n",
       "body .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       "body .w { color: #bbbbbb } /* Text.Whitespace */\n",
       "body .mf { color: #666666 } /* Literal.Number.Float */\n",
       "body .mh { color: #666666 } /* Literal.Number.Hex */\n",
       "body .mi { color: #666666 } /* Literal.Number.Integer */\n",
       "body .mo { color: #666666 } /* Literal.Number.Oct */\n",
       "body .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       "body .sc { color: #BA2121 } /* Literal.String.Char */\n",
       "body .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       "body .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       "body .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       "body .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       "body .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       "body .sx { color: #008000 } /* Literal.String.Other */\n",
       "body .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       "body .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       "body .ss { color: #19177C } /* Literal.String.Symbol */\n",
       "body .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       "body .vc { color: #19177C } /* Name.Variable.Class */\n",
       "body .vg { color: #19177C } /* Name.Variable.Global */\n",
       "body .vi { color: #19177C } /* Name.Variable.Instance */\n",
       "body .il { color: #666666 } /* Literal.Number.Integer.Long */\n",
       "\n",
       "  </style>\n",
       "</head>\n",
       "<body>\n",
       "<h2></h2>\n",
       "\n",
       "<div class=\"highlight\"><pre><span class=\"c\">#!/bin/sh</span>\n",
       "<span class=\"c\">#$ -S /bin/bash</span>\n",
       "<span class=\"c\">#$ -cwd</span>\n",
       "<span class=\"c\">#$ -N process_tchain</span>\n",
       "<span class=\"c\"># number of tasks</span>\n",
       "<span class=\"c\">#$ -t 1-20</span>\n",
       "<span class=\"c\">#$ -e log_files/$JOB_ID-$TASK_ID.err</span>\n",
       "<span class=\"c\">#$ -o log_files/$JOB_ID-$TASK_ID.out</span>\n",
       "\n",
       "<span class=\"c\"># set enviroment</span>\n",
       "<span class=\"nb\">echo</span> <span class=\"s2\">&quot;Setting up CMSSW env (for modern ROOT and gcc)&quot;</span>\n",
       "<span class=\"nb\">source</span> /cvmfs/cms.cern.ch/cmsset_default.sh\n",
       "<span class=\"nb\">export </span><span class=\"nv\">SCRAM_ARCH</span><span class=\"o\">=</span>slc6_amd64_gcc491 \n",
       "<span class=\"c\"># set area</span>\n",
       "<span class=\"nb\">cd</span> <span class=\"nv\">$PWD</span>/releases/CMSSW_7_4_0/src\n",
       "<span class=\"nb\">eval</span> <span class=\"sb\">`</span>scramv1 runtime -sh<span class=\"sb\">`</span>\n",
       "<span class=\"nb\">cd</span> - &amp;&gt; /dev/null \n",
       "<span class=\"nb\">echo</span> <span class=\"s2\">&quot;CMSSW setup completed&quot;</span>\n",
       "\n",
       "<span class=\"c\"># add program to PATH</span>\n",
       "<span class=\"nv\">PROGRAM_BIN</span><span class=\"o\">=</span><span class=\"s2\">&quot;$PWD/program/bin&quot;</span>\n",
       "<span class=\"nv\">PATH</span><span class=\"o\">=</span><span class=\"nv\">$PROGRAM_BIN</span>:<span class=\"nv\">$PATH</span>\n",
       "\n",
       "<span class=\"c\"># path with the text filewith input file names</span>\n",
       "<span class=\"nv\">INPUTFILESFILE</span><span class=\"o\">=</span><span class=\"s2\">&quot;$PWD/inputfiles.txt&quot;</span>\n",
       "<span class=\"nv\">INPUTFILE</span><span class=\"o\">=</span><span class=\"k\">$(</span>awk <span class=\"s2\">&quot;NR==$SGE_TASK_ID&quot;</span> <span class=\"nv\">$INPUTFILESFILE</span><span class=\"k\">)</span>\n",
       "<span class=\"nv\">OUTPUTDIR</span><span class=\"o\">=</span><span class=\"s2\">&quot;output_files/&quot;</span>\n",
       "<span class=\"nv\">OUTPUTFILE</span><span class=\"o\">=</span><span class=\"nv\">$OUTPUTDIR</span><span class=\"s2\">&quot;output&quot;</span><span class=\"k\">$(</span>basename <span class=\"nv\">$INPUTFILE</span><span class=\"k\">)</span>\n",
       "\n",
       "<span class=\"nb\">echo</span> <span class=\"s2\">&quot;Input  File: &quot;</span><span class=\"nv\">$INPUTFILE</span>\n",
       "<span class=\"nb\">echo</span> <span class=\"s2\">&quot;Output File: &quot;</span><span class=\"nv\">$OUTPUTFILE</span>\n",
       "\n",
       "<span class=\"c\"># execute</span>\n",
       "process_tchain -i <span class=\"nv\">$INPUTFILE</span> -o <span class=\"nv\">$OUTPUTFILE</span>\n",
       "</pre></div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import highlight_source_bash\n",
    "highlight_source_bash(\"process_tchain_array.sge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from array jobs, many DRM installations (as the one present at IFCA) allow to send job to parallel queues, using the *parallel enviroment* flag (e.g. *-pe mpi*, which uses a special queue integrated with MPI). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 DRMAA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all the communication for submitting and controlling job with the DRM has been done using the command line interface specific for SGE. However, the [Open Grid Forum](https://www.ogf.org/ogf/doku.php) mantains the [Distributed Resource Management Application API (DRMAA)](http://www.drmaa.org/) for programmatic and tightly coupled access to cluster, grid and cloud systems. The advantages of DRMAA over the specific tools of each DRM is that job submission, control and monitoring can be standardized and controlled by different applications or programs. Most of the available DRM vendor have implemented the DRMAA specification and bindings of the API are available in several programming languages (e.g. C, C++, Java or Python)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of the use of the [Python DRMAA binding](https://github.com/pygridtools/drmaa-python) will be provided in this document (based on DRMMA documentation). To check that everything is working, we can check that a drmma session can be initialized and retrieve some information about the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A DRMAA object was created\n",
      "Supported contact strings: session=cloudprv-10-3.3280.125413370\n",
      "Supported DRM systems: SGE 8.1.4\n",
      "Supported DRMAA implementations: SGE 8.1.4\n",
      "Version 1.0\n",
      "Exiting\n"
     ]
    }
   ],
   "source": [
    "import drmaa\n",
    "\n",
    "# initialize session\n",
    "s = drmaa.Session()\n",
    "s.initialize()\n",
    "# get information about session\n",
    "print 'A DRMAA object was created'\n",
    "print 'Supported contact strings: ' + s.contact\n",
    "print 'Supported DRM systems: ' + str(s.drmsInfo)\n",
    "print 'Supported DRMAA implementations: ' + str(s.drmaaImplementation)\n",
    "print 'Version ' + str(s.version)\n",
    "# exit session\n",
    "print 'Exiting'\n",
    "s.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the DRMAA for simple job submission and getting job status in a programmatic way (instead of using *qsub and qstat*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating job template\n",
      "Your job has been submitted with ID 5930270\n",
      "Checking 0 of 3 times\n",
      "job is queued and active\n",
      "Checking 1 of 3 times\n",
      "job finished normally\n",
      "Checking 2 of 3 times\n",
      "job finished normally\n",
      "Cleaning up\n"
     ]
    }
   ],
   "source": [
    "import drmaa\n",
    "import os \n",
    "import time\n",
    "\n",
    "# create drmaa session\n",
    "with drmaa.Session() as s:\n",
    "    print('Creating job template')\n",
    "    jt = s.createJobTemplate()\n",
    "    jt.nativeSpecification = u\"-b no -cwd -shell yes\"\n",
    "    jt.remoteCommand = os.path.join(os.getcwd(), 'sleeper.sh')\n",
    "    jt.args = ['42', 'Simon says:']\n",
    "    jt.joinFiles=True\n",
    "\n",
    "    jobid = s.runJob(jt)\n",
    "    print('Your job has been submitted with ID %s' % jobid)\n",
    "\n",
    "    # decode status\n",
    "    decodestatus = {drmaa.JobState.UNDETERMINED: 'process status cannot be determined',\n",
    "                    drmaa.JobState.QUEUED_ACTIVE: 'job is queued and active',\n",
    "                    drmaa.JobState.SYSTEM_ON_HOLD: 'job is queued and in system hold',\n",
    "                    drmaa.JobState.USER_ON_HOLD: 'job is queued and in user hold',\n",
    "                    drmaa.JobState.USER_SYSTEM_ON_HOLD: 'job is queued and in user and system hold',\n",
    "                    drmaa.JobState.RUNNING: 'job is running',\n",
    "                    drmaa.JobState.SYSTEM_SUSPENDED: 'job is system suspended',\n",
    "                    drmaa.JobState.USER_SUSPENDED: 'job is user suspended',\n",
    "                    drmaa.JobState.DONE: 'job finished normally',\n",
    "                    drmaa.JobState.FAILED: 'job finished, but failed'}\n",
    "\n",
    "    # check for status\n",
    "    for ix in range(3):\n",
    "        print('Checking %s of 3 times' % ix)\n",
    "        print decodestatus[s.jobStatus(jobid)]\n",
    "        time.sleep(10)\n",
    "\n",
    "    print('Cleaning up')\n",
    "    s.deleteJobTemplate(jt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example create an array job (with 10 tasks) and waits for all of them to finish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating job template\n",
      "Your job has been submitted with id [u'5930275.1', u'5930275.2', u'5930275.3', u'5930275.4', u'5930275.5', u'5930275.6', u'5930275.7', u'5930275.8', u'5930275.9', u'5930275.10']\n",
      "Collecting job 5930275.1\n",
      "Job: 5930275.1 finished with status True\n",
      "Collecting job 5930275.2\n",
      "Job: 5930275.2 finished with status True\n",
      "Collecting job 5930275.3\n",
      "Job: 5930275.3 finished with status True\n",
      "Collecting job 5930275.4\n",
      "Job: 5930275.4 finished with status True\n",
      "Collecting job 5930275.5\n",
      "Job: 5930275.5 finished with status True\n",
      "Collecting job 5930275.6\n",
      "Job: 5930275.6 finished with status True\n",
      "Collecting job 5930275.7\n",
      "Job: 5930275.7 finished with status True\n",
      "Collecting job 5930275.8\n",
      "Job: 5930275.8 finished with status True\n",
      "Collecting job 5930275.9\n",
      "Job: 5930275.9 finished with status True\n",
      "Collecting job 5930275.10\n",
      "Job: 5930275.10 finished with status True\n",
      "Cleaning up\n"
     ]
    }
   ],
   "source": [
    "import drmaa\n",
    "import os \n",
    "\n",
    "# create drmaa session\n",
    "with drmaa.Session() as s:\n",
    "    print 'Creating job template'\n",
    "    jt = s.createJobTemplate()\n",
    "    jt.nativeSpecification = u\"-b no -cwd -shell yes\"\n",
    "    jt.remoteCommand = os.getcwd() + '/sleeper.sh'\n",
    "    jt.args = ['42','Simon says:']\n",
    "    jt.joinFiles=True\n",
    "    # send array of jobs\n",
    "    joblist = s.runBulkJobs(jt,1,10,1)\n",
    "    print 'Your job has been submitted with id ' + str(joblist)\n",
    "    s.synchronize(joblist, drmaa.Session.TIMEOUT_WAIT_FOREVER, False)\n",
    "    for curjob in joblist:\n",
    "        print 'Collecting job ' + curjob\n",
    "        retval = s.wait(curjob, drmaa.Session.TIMEOUT_WAIT_FOREVER)\n",
    "        print 'Job: ' + str(retval.jobId) + ' finished with status '+ str(retval.hasExited)\n",
    "    print 'Cleaning up'\n",
    "    s.deleteJobTemplate(jt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Complementary approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last section, some examples of advanced usage of DRMs were provided. However, the command line usage of DRMs is good for simple job submission but do not allows for complex parallel workloads and it specific for each DRM. The DRMMA approach, while powerful, is in general too low level for integration in day to day cluster computing tasks. In this section, some modern complementary approaches to cluster parallel computing will be reviewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Jug: Simple Task Based Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first alternative approach that is going to be explored is [*jug*](https://github.com/luispedro/jug), a task-based parallelization framework written in Python. Basically it allows to write code (also libraries and programs in other languages) that is broken into tasks (which can have other task as dependencies) and run on different processors of workers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting characteristic of this framework is that all communication between processes and workers is done through the filesystem (also works using a networked filesystem as GPFS). Hence, this framework makes the trivial the parallelization of complex processing workflows in a computing cluster. Another advantage is that workers can be added or removed at any time during execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework automatically takes care of distributing tasks between all avaliable workers and interchanging all required information between task. The final and intermediate results are persisted to the filesystem and can be easily explored after the computation. While *jug* can introduce a huge overhead for many small tasks (filesystem communication overhead), it can be reasonably performant and incredible flexible for workflows that can be broken into larger tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example adapted from the [framework documentation](https://jug.readthedocs.org/en/latest/text-example.html) is going to be used to demonstrate its use. In the example, the aim is to download the Wikipedia pages for the British members of Parlament (MPs) listed on a list (i.e. *MPs.txt*) and extract the words that are unique for each one of them (that somehow will characterize each MP). The full code for this task is provided in *jugfile.py*, but here we will only be interested in how the job is broken into independent tasks, which can be inferred from the next code fragment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "counts = []\n",
    "for mp in file('MPs.txt'):\n",
    "    mp = mp.strip()\n",
    "    document = Task(getdata, mp)\n",
    "    counts.append(Task(countwords, mp, document))\n",
    "avgs = Task(addcounts, counts)\n",
    "results = []\n",
    "for c in counts:\n",
    "    results.append(Task(divergence,avgs, len(counts), c))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is broken into four different tasks: getdata (from Wikipedia for each MP), countwords (in a filename), addcounts (from all the files) and divergence (returns the words that are specific for each document). To make computation slower, some sleep time has been added to all of the tasks. We can check the initial status of the computation (e.g. total number of task to be executed) by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Waiting       Ready    Finished     Running  Task name                     \r\n",
      "--------------------------------------------------------------------------------\r\n",
      "         656           0           0           0  jugfile.countwords            \r\n",
      "         656           0           0           0  jugfile.divergence            \r\n",
      "           1           0           0           0  jugfile.addcounts             \r\n",
      "           0         656           0           0  jugfile.getdata               \r\n",
      "................................................................................\r\n",
      "        1313         656           0           0  Total                         \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jug status jugfile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, no task as been executed yet and there are a total of 1313 tasks to be executed (some of them are not ready because they are dependent on other tasks). In order start executing them, this command has to be called:\n",
    "\n",
    "    jug execute jugfile.py\n",
    "    \n",
    "While this can be directly done in the login node (even many times as different processes), we are going to call this command from the compute nodes (which are automatically coordinated through the filesystem). Therefore, the previous command (after setting up the right gcc and Python enviroment) can be executed as a SGE task array in as many compute nodes as wanted. A SGE script for that is given at *jug_task_array.sge*, which can then be sent to the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your job-array 5933317.1-20:1 (\"jug_task_array\") has been submitted\r\n"
     ]
    }
   ],
   "source": [
    "!qsub -t 1-20 jug_task_array.sge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some time, progress can be checked again with the *jug status* command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Waiting       Ready    Finished     Running  Task name                     \r\n",
      "--------------------------------------------------------------------------------\r\n",
      "         588           0          51          17  jugfile.countwords            \r\n",
      "         656           0           0           0  jugfile.divergence            \r\n",
      "           1           0           0           0  jugfile.addcounts             \r\n",
      "           0         588          68           0  jugfile.getdata               \r\n",
      "................................................................................\r\n",
      "        1245         588         119          17  Total                         \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jug status jugfile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all task which verify the dependencies are being automatically run at the workers until all of them finish. We could also add (or quit) some more workers at any time. After a while (due to fake deadtimes added), all tasks are finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Waiting       Ready    Finished     Running  Task name                     \r\n",
      "--------------------------------------------------------------------------------\r\n",
      "           0           0         656           0  jugfile.getdata               \r\n",
      "           0           0         656           0  jugfile.countwords            \r\n",
      "           0           0         645          11  jugfile.divergence            \r\n",
      "           0           0           1           0  jugfile.addcounts             \r\n",
      "................................................................................\r\n",
      "           0           0        1958          11  Total                         \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!jug status jugfile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results have been saved to the filesystem (in the *jugfile.jugdata* directory). We can for example list the 8 first unique words for the first 10 MPs in the list (or any arbitrary computation with the results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richard Benyon:  family august 20 contested again estate newbury rendel\n",
      "Angus MacNeil:  westminster hotel teacher incident honours abuse best inquiry\n",
      "Richard Younger-Ross:  mr voting claims proposed water susan walton profile\n",
      "Bob Laxton:  representative union derby boycotting higher 1961 lamb technology\n",
      "Sarah Teather:  she her liberal september group democrat 2007 4\n",
      "Bob Marshall-Andrews:  you mr rebelled dowd own 9 widely 10\n",
      "Virendra Sharma:  donation ealing register letter detail relationship telegraph vaz\n",
      "Hywel Francis:  voted favour wales chair dr could allowing independent\n",
      "Jacqui Smith:  she her home it over said i expenses\n",
      "Angus Robertson:  snp scottish spokesperson affairs westminster european cinema amongst\n"
     ]
    }
   ],
   "source": [
    "import jug\n",
    "import jug.task\n",
    "jug.init('jugfile.py', 'jugfile.jugdata')\n",
    "import jugfile\n",
    "results = jug.task.value(jugfile.results)\n",
    "for mp,r in zip(file('MPs.txt'), results)[:10]:\n",
    "    mp = mp.strip()\n",
    "    print mp + \": \"+ \" \"+\" \".join(map(str,r[:8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 IPython Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The [IPython](http://ipython.org/) suite (which will be named Jupyter in future releases and changed to be language agnostic) defines a powerful and flexible architecture for parallel computing. [IPython parallel](http://ipython.org/ipython-doc/stable/parallel/index.html) can support many types of parallelism:\n",
    "   - Single program, multiple data (SPMD) parallelism.\n",
    "   - Multiple program, multiple data (MPMD) parallelism.\n",
    "   - Message passing using MPI.\n",
    "   - Task farming.\n",
    "   - Data parallel.\n",
    "   - Combinations of these approaches.\n",
    "   - Custom user defined approaches.\n",
    "\n",
    "Furthermore, IPython Parallel enables all types of parallel applications to be developed, executed, debugged and monitored interactively. Hence, this parallel framework can be applied to diverse use cases, including:\n",
    "   - Easy parallelization of embarrassingly parallel problems to several processes, computers or a cluster.\n",
    "   - Steering traditional MPI applications on a supercomputer from an IPython Notebook.\n",
    "   - Analyzing and visualizing large datasets (that could be remote and/or distributed) interactively.\n",
    "   - Tying together multiple MPI jobs running on different systems into one giant distributed and parallel system.\n",
    "\n",
    "This system is relevant to cluster computing because it is designed in a way it can be easily integrated with several DRMs (e.g. SGE or PBS) using the [*ipcluster*](https://ipython.org/ipython-doc/dev/parallel/parallel_process.html) utilities. For example, using that command a total of 48 engines have been started on the IFCA cluster. We can easily connect to the controller of those engines and show the corresponding ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n"
     ]
    }
   ],
   "source": [
    "from IPython.parallel import Client\n",
    "rc = Client()\n",
    "print rc.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can steer those engines arbitrarily. For example, we can make a Monte Carlo estimation of $\\pi$ for each of the nodes and get the results asyncronously (using a distributed view):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monte_carlo_pi(n):\n",
    "    if (n < 1) : return 0\n",
    "    n_shots = 0\n",
    "    for i in range(n):\n",
    "        x = np.random.random()\n",
    "        y = np.random.random()\n",
    "        r = np.sqrt(x*x+y*y)\n",
    "        if ( r<=1 ): n_shots = n_shots + 1\n",
    "    return 4.0*float(n_shots)/float(n) \n",
    "\n",
    "dview=rc[:]\n",
    "dview.execute('import numpy as np')\n",
    "ar = dview.apply_async(monte_carlo_pi, 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the computation on all the engines has finished we can get the results as an array and compute the mean as a better $\\pi$ estimation (beware that this method for estimating $\\pi$ is much worse than the Machin's series used before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14188, 3.141048, 3.141392, 3.139952, 3.137364, 3.140196, 3.142076, 3.140796, 3.142112, 3.1421, 3.140496, 3.142392, 3.1393, 3.139176, 3.13872, 3.140696, 3.144952, 3.142044, 3.139472, 3.142672, 3.14154, 3.142648, 3.14134, 3.138248, 3.142972, 3.140476, 3.140468, 3.141784, 3.142796, 3.142076, 3.142244, 3.141148, 3.141312, 3.144044, 3.141548, 3.141272, 3.142988, 3.145472, 3.137328, 3.144864, 3.14276, 3.14266, 3.139764, 3.13996, 3.140784, 3.14116, 3.143836, 3.141796]\n"
     ]
    }
   ],
   "source": [
    "pi_list = ar.get()\n",
    "print pi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value for pi: 3.14142\n"
     ]
    }
   ],
   "source": [
    "print \"Mean value for pi: {:2.5f}\".format(np.mean(pi_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as an example of how this tool can speed up day to day data analysis tasks, a real world example is going to be used as an example. The [use case](http://chidlow.id.au/blog/2013/09/24/distributed-computing-with-ipython/) is about optimizing the hyper-parameters of a support vector machine which gives a better cross validation score. The scikit-learn module is required and the full example code is provided at *svm_params_crossval.py*. The program will compare the execution time in serial and in parallel using the 48 engines previously started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing numpy on engine(s)\n",
      "importing svm from sklearn on engine(s)\n",
      "\n",
      "Running 150 tasks:\n",
      "    Done  130 out of  150 | elapsed:    7.3s remaining:    1.1s\n",
      "    Done  150 out of  150 | elapsed:    7.9s remaining:    0.0s\n",
      "\n",
      "Parallel speedup: 4315%\n",
      "\n",
      "Best: C = 1000000.0, gamma = 0.0001, err = 2.0%\n",
      "\n",
      "[[ 100.    100.    100.    100.    100.    100.    100.    100.    100.  ]\n",
      " [ 100.    100.    100.     92.     12.      6.    100.    100.    100.  ]\n",
      " [ 100.    100.     79.33   10.      2.67    5.33   11.33   49.33   63.33]\n",
      " [ 100.     78.67   10.      4.      4.      6.     11.33   48.     63.33]\n",
      " [  78.     10.      4.      3.33    4.67    6.67   11.33   48.     63.33]\n",
      " [  10.      4.      3.33    4.67    6.67    6.67   11.33   48.     63.33]\n",
      " [   4.      3.33    3.33    4.67    7.33    6.67   11.33   48.     63.33]\n",
      " [   3.33    3.33    2.67    4.67    7.33    6.67   11.33   48.     63.33]\n",
      " [   3.33    2.      3.33    6.67    7.33    6.67   11.33   48.     63.33]\n",
      " [   4.      4.      4.67    6.      7.33    6.67   11.33   48.     63.33]\n",
      " [   4.67    4.      6.      6.      7.33    6.67   11.33   48.     63.33]]\n",
      "\n",
      "Total time:    8.2s\n"
     ]
    }
   ],
   "source": [
    "%run svm_params_crossval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the results, the use of IPython parallel at the cluster is able to speed up the task in a $4315~\\%$, so the problem (which is an embarrassingly parallel problem) can take an important advantage of parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Modern Cluster Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from the cluster computing tools that have been mentioned up to this point. It is worth mentioning two open-source frameworks that currently are de facto standards for cluster computing: [Apache Hadoop](http://hadoop.apache.org/) and [Apache Spark](https://spark.apache.org/). They could not be easily installed at the IFCA cluster so no usage examples are provided.\n",
    "\n",
    "The Hadoop framework, written in Java, consist on the combination of a distributed file system (HDFS) and a processing engine (MapReduce). Map Reduce is a programming model (inspired in functional programming) for processing and generating large data sets with a parallel, distributed algorithm on a cluster. Basically is the combination of a *Map()* (applied per element) and a *Reduce()* (applied to several *Map()* results), which can be easily scaled to very large datasets.\n",
    "\n",
    "Apache Spark follows a similar approach (in fact could use HDFS and Hadoop administration tools), but allows programs to keep data in memory and query it repeteatly making it faster and more appropiate for more complex task (e.g. machine learning or graph processing). With these tools, very large cluster computing workflows can be specified with a higher level of abstraction, so they are replacing traditional DRMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document, different approaches for cluster computing have been explored. After introducing a few basic concepts for cluster computing, some advanced uses of SGE have been tested. The usage of DRMAA for programmatically submit and monitor jobs in different DRMs have also been interactively demonstrated at IFCA computing cluster. After highlighting the drawbacks of DRMs for complex workflows, *jug* and *IPython Parallel* have been explored as complementary tools and some real world examples of their use have been provided. Finally, a basic description of the MapReduce concept (and their most popular open-source implementations) as an alternative to traditional cluster computing has been included."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
